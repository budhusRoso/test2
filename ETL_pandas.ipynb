{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad02d8f7",
   "metadata": {},
   "source": [
    "# Pandas ETL commands.\n",
    "\n",
    "## 1.Extract(E)...\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# CSV\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Excel\n",
    "df = pd.read_excel('data.xlsx')\n",
    "\n",
    "# JSON\n",
    "df = pd.read_json('data.json')\n",
    "\n",
    "# Parquet\n",
    "df = pd.read_parquet('data.parquet')\n",
    "\n",
    "# SQL\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('your_connection_string')\n",
    "df = pd.read_sql('SELECT * FROM table', con=engine)\n",
    "```\n",
    "## 2.Load(L)...\n",
    "\n",
    "```python\n",
    "# To CSV\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "# To Excel\n",
    "df.to_excel('output.xlsx', index=False)\n",
    "\n",
    "# To Parquet\n",
    "df.to_parquet('output.parquet', index=False)\n",
    "\n",
    "# To SQL\n",
    "df.to_sql('table_name', con=engine, if_exists='replace', index=False)\n",
    "```\n",
    "\n",
    "## 3.Transform(T).\n",
    "\n",
    "### 3.1 Column Operations.\n",
    "\n",
    "```python \n",
    "# Rename columns\n",
    "df.rename(columns={'old_name': 'new_name'}, inplace=True)\n",
    "\n",
    "# Add a new column\n",
    "df['new_col'] = default_value\n",
    "\n",
    "# Drop columns\n",
    "df.drop(columns=['col1', 'col2'], inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['col3', 'col1', 'col2']]\n",
    "\n",
    "# Change column data types\n",
    "df['col'] = df['col'].astype('int64')\n",
    "\n",
    "# Rename all columns\n",
    "df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "```\n",
    "\n",
    "### 3.2 Cleaning & Missing Data.\n",
    "\n",
    "```python\n",
    "# Drop rows with any missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Fill missing values\n",
    "df.fillna(value=0, inplace=True)\n",
    "\n",
    "# Fill with method\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Replace specific values\n",
    "df.replace({'old_val': 'new_val'}, inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "```\n",
    "\n",
    "### 3.3 Filtering & Selecting.\n",
    "\n",
    "```python\n",
    "# Filter rows\n",
    "df = df[df['amount'] > 1000]\n",
    "\n",
    "# Select multiple conditions\n",
    "df = df[(df['age'] > 25) & (df['country'] == 'US')]\n",
    "\n",
    "# Query syntax\n",
    "df.query('amount > 1000 and region == \"West\"')\n",
    "\n",
    "# Use isin\n",
    "df[df['category'].isin(['A', 'B'])]\n",
    "\n",
    "```\n",
    "\n",
    "### 3.4 Aggregation & Grouping.\n",
    "\n",
    "```python\n",
    "# Simple groupby\n",
    "df.groupby('category')['amount'].sum()\n",
    "\n",
    "# Multiple aggregates\n",
    "df.groupby('category').agg({'amount': ['sum', 'mean'], 'quantity': 'count'})\n",
    "\n",
    "# Reset index after groupby\n",
    "df_grouped.reset_index(inplace=True)\n",
    "\n",
    "# Group and apply custom function\n",
    "df.groupby('user_id').apply(lambda x: x['score'].mean())\n",
    "\n",
    "```\n",
    "\n",
    "### 3.5 Join / Merge / Combine.\n",
    "\n",
    "```python\n",
    "# Inner join\n",
    "df_merged = pd.merge(df1, df2, on='id', how='inner')\n",
    "\n",
    "# Left join\n",
    "pd.merge(df1, df2, on='id', how='left')\n",
    "\n",
    "# Join on index\n",
    "df1.join(df2, how='outer')\n",
    "\n",
    "# Concatenate rows\n",
    "df_all = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# Concatenate columns\n",
    "df_combined = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "```\n",
    "\n",
    "### 3.6 Apply & Map Functions.\n",
    "\n",
    "```python \n",
    "# Apply row-wise or column-wise\n",
    "df['log_amount'] = df['amount'].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# Apply custom function to multiple columns\n",
    "df['full_name'] = df[['first_name', 'last_name']].apply(lambda x: f\"{x[0]} {x[1]}\", axis=1)\n",
    "\n",
    "# Use map for value replacement\n",
    "df['gender'] = df['gender'].map({'M': 'Male', 'F': 'Female'})\n",
    "\n",
    "```\n",
    "\n",
    "### 3.7 String Operations.\n",
    "\n",
    "```python \n",
    "df['col'] = df['col'].str.lower()\n",
    "df['col'] = df['col'].str.strip()\n",
    "df['col'] = df['col'].str.replace('old', 'new', regex=True)\n",
    "df['email_domain'] = df['email'].str.split('@').str[1]\n",
    "\n",
    "```\n",
    "\n",
    "### 3.8 DateTime Handling.\n",
    "\n",
    "```python\n",
    "# Convert to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Extract parts\n",
    "df['year'] = df['timestamp'].dt.year\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['day'] = df['timestamp'].dt.day\n",
    "\n",
    "# Date difference\n",
    "df['days_since_signup'] = (pd.Timestamp.now() - df['signup_date']).dt.days\n",
    "\n",
    "# Filter by date\n",
    "df[df['timestamp'] >= '2023-01-01']\n",
    "\n",
    "```\n",
    "\n",
    "### 3.9 Pivot & Reshape.\n",
    "\n",
    "```python\n",
    "# Pivot\n",
    "df_pivot = df.pivot_table(index='date', columns='product', values='sales', aggfunc='sum')\n",
    "\n",
    "# Melt (unpivot)\n",
    "df_melted = df.melt(id_vars='date', var_name='product', value_name='sales')\n",
    "\n",
    "# Stack / unstack\n",
    "df_stacked = df.stack()\n",
    "df_unstacked = df_stacked.unstack()\n",
    "\n",
    "```\n",
    "\n",
    "### 3.10 Binning / Bucketing.\n",
    "\n",
    "``` python\n",
    "# Fixed bins\n",
    "df['bucket'] = pd.cut(df['age'], bins=[0, 18, 30, 50, 100], labels=['teen', 'young', 'middle', 'senior'])\n",
    "\n",
    "# Quantile-based bins\n",
    "df['income_quartile'] = pd.qcut(df['income'], q=4)\n",
    "\n",
    "``` \n",
    "\n",
    "### 3.11 Validation & Checking.\n",
    "\n",
    "``` python\n",
    "# Check for duplicates\n",
    "df.duplicated().sum()\n",
    "\n",
    "# Assert column types\n",
    "assert df['age'].dtype == 'int64'\n",
    "\n",
    "# Ensure unique keys\n",
    "assert df['id'].is_unique\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
